{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import open_clip\n",
    "from tqdm.notebook import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_clip_embedding_from_PIL_image(image):\n",
    "#     image_tensor = preprocess(image).unsqueeze(0)\n",
    "#     with torch.no_grad():\n",
    "#         embedding = model.encode_image(image_tensor).squeeze().numpy()\n",
    "#     return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_embeddings(image_directory):\n",
    "#     embedding_list = []\n",
    "#     id_list = []\n",
    "\n",
    "#     for image_name in os.listdir(image_directory):\n",
    "#         image_path = os.path.join(image_directory, image_name)\n",
    "#         item_id = os.path.splitext(image_name)[0]\n",
    "#         id_list.append(int(item_id))\n",
    "#         try:\n",
    "#             image = Image.open(image_path).convert(\"RGB\")\n",
    "#             embedding = get_clip_embedding_from_PIL_image(image)\n",
    "#             embedding_list.append(embedding)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing {image_name}: {e}\")\n",
    "        \n",
    "#     return embedding_list, id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成嵌入向量\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "class_names = sorted([d for d in os.listdir('dataset') if os.path.isdir(f'dataset/{d}')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a024cd6e92a54f25809dbe562399c743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "categories:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f462342bbb44aada03938c708a92886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "01:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269c6df1520c4e33b7c73f3f42424ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "02:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd503c9aa0a476fb2401955138451ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "03:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2628785db094e26b11209589c7b3ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "04:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf17503b4f9c4e449942053699a86072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "05:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea119964eebf47dea819fa477fcab908",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "06:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d5854e6cd543518b226e615f8fd5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "07:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d76e082f14d423781716ca4a0d43073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "08:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0269ec4eed7241c2967bb948db4534d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "09:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca43fd8fb8b4c7e97aa8add897e2da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "10:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c53e4ae0f1486b8570afa7ef018960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "11:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9652dd6a4045b6addab41e641c592c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "12:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for label_idx, class_name in enumerate(tqdm(class_names, desc='categories')):\n",
    "    class_dir = f'dataset/{class_name}'\n",
    "    for img_name in tqdm(os.listdir(class_dir), desc=class_name, leave=False):\n",
    "        try:\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "            \n",
    "            # 预处理和推理\n",
    "            image_tensor = preprocess(image).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                embedding = model.encode_image(image_tensor).cpu().numpy()\n",
    "            \n",
    "            all_embeddings.append(embedding)\n",
    "            all_labels.append(label_idx)\n",
    "        except Exception as e:\n",
    "            print(f\"处理 {img_path} 失败：{str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成嵌入完成！总样本数：600\n"
     ]
    }
   ],
   "source": [
    "# 保存结果\n",
    "np.save('animal_embeddings.npy', np.concatenate(all_embeddings, axis=0))\n",
    "np.save('animal_labels.npy', np.array(all_labels))\n",
    "print(f\"生成嵌入完成！总样本数：{len(all_labels)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
